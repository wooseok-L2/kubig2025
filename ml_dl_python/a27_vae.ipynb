{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XtyFSClpDlt",
        "outputId": "b2746f8f-99f8-4151-8fa7-0833cab328e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7vbl2f4upjus"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:04<00:00, 2015600.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 164680.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 967852.33it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8218519.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0qappGWs96t",
        "outputId": "414e74d1-30cf-4007-db66-68e906d20efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
            "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
            "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
            "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
            "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
            "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
            "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
            "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
            "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
            "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
            "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
            "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
            "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
            "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
            "       dtype=torch.uint8)\n",
            "tensor(5)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(train_dataset.data.shape)\n",
        "# 첫번째 데이터 출력\n",
        "print(train_dataset.data[0])\n",
        "# matplot 으로 출력\n",
        "plt.imshow(train_dataset.data[0], cmap=\"gray\")\n",
        "print(train_dataset.targets[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1Jze_V82qXkj"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        self.encoder_lin = nn.Sequential(\n",
        "            nn.Linear(3 * 3 * 32, 128), nn.ReLU(True), nn.Linear(128, encoded_space_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_cnn(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.encoder_lin(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, encoded_space_dim, fc2_input_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder_lin = nn.Sequential(\n",
        "            nn.Linear(encoded_space_dim, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 3 * 3 * 32),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.decoder_lin(x)\n",
        "        x = self.unflatten(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deaTF5CwtrlX",
        "outputId": "a13d21b1-ba48-4305-bfbe-b0ae9598a5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (encoder_cnn): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (encoder_lin): Sequential(\n",
            "    (0): Linear(in_features=288, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(encoded_space_dim=2, fc2_input_dim=128)\n",
        "decoder = Decoder(encoded_space_dim=2, fc2_input_dim=128)\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "params_to_optimize = [\n",
        "    {\"params\": encoder.parameters()},\n",
        "    {\"params\": decoder.parameters()},\n",
        "]\n",
        "\n",
        "optimizer = optim.Adam(params_to_optimize, lr=0.001, weight_decay=1e-05)\n",
        "loss_fn = nn.MSELoss()\n",
        "print(encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K0fO6gMkuPaq"
      },
      "outputs": [],
      "source": [
        "def add_noise(inputs, noise_factor=0.3):\n",
        "    noisy = inputs + torch.randn_like(inputs) * noise_factor\n",
        "    noisy = torch.clip(noisy, 0.0, 1.0)\n",
        "    return noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "LR3ryvpH33HJ",
        "outputId": "f1d50638-3f3e-4196-8c33-730cff4f01f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = test_dataset.data[1].unsqueeze(0).float().to(device)\n",
        "print(test_dataset.data[1].shape)\n",
        "print(img.shape)\n",
        "noisy_img = add_noise(img, noise_factor=0.3).to(device)\n",
        "print(noisy_img.shape)\n",
        "plt.imshow(img.cpu().squeeze().numpy(), cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(noisy_img.cpu().squeeze().numpy(), cmap=\"gray\")\n",
        "plt.show()\n",
        "rec_img = decoder(\n",
        "    encoder(test_dataset.data[0].float().to(device).reshape(1, 1, 28, 28))\n",
        ")\n",
        "rec_img = decoder(encoder(noisy_img.reshape(1, 1, 28, 28)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kZPtOQ4vuPdb"
      },
      "outputs": [],
      "source": [
        "def plot_ae_outputs(encoder, decoder, n=15, noise_factor=0.3):\n",
        "    plt.figure(figsize=(10, 4.5))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(3, n, i + 1)\n",
        "        img = test_dataset.data[i].unsqueeze(0).float().to(device)\n",
        "        noisy_img = add_noise(img, noise_factor).to(device)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            rec_img = decoder(encoder(noisy_img.reshape(-1, 1, 28, 28)))\n",
        "        plt.imshow(img.cpu().squeeze().numpy(), cmap=\"gray\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title(\"Original images\")\n",
        "        ax = plt.subplot(3, n, i + 1 + n)\n",
        "        plt.imshow(noisy_img.cpu().squeeze().numpy(), cmap=\"gray\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title(\"Noisy Input\")\n",
        "\n",
        "        ax = plt.subplot(3, n, i + 1 + n * 2)\n",
        "        plt.imshow(rec_img.cpu().squeeze().numpy(), cmap=\"gray\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        if i == n // 2:\n",
        "            ax.set_title(\"Reconstructed Input\")\n",
        "        plt.subplots_adjust(\n",
        "            left=0.1, bottom=0.1, right=0.7, top=0.9, wspace=0.3, hspace=0.3\n",
        "        )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "q5F-9x2P0Ubk"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    encoder, decoder, device, dataloader, loss_fn, optimizer, noise_factor=0.3\n",
        "):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = []\n",
        "    for image_batch, _ in dataloader:\n",
        "        image_batch = image_batch.to(device)\n",
        "        noisy_batch = add_noise(image_batch, noise_factor)\n",
        "        encoded_data = encoder(noisy_batch)\n",
        "        decoded_data = decoder(encoded_data)\n",
        "        loss = loss_fn(decoded_data, image_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.detach().cpu().numpy())\n",
        "    return np.mean(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UarA-_TV0UhZ"
      },
      "outputs": [],
      "source": [
        "def test_epoch(encoder, decoder, device, dataloader, loss_fn, noise_factor=0.3):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    with torch.no_grad():\n",
        "        conc_out = []\n",
        "        conc_label = []\n",
        "        for image_batch, _ in dataloader:\n",
        "            image_batch = image_batch.to(device)\n",
        "            noisy_batch = add_noise(image_batch, noise_factor)\n",
        "            encoded_data = encoder(noisy_batch)\n",
        "            decoded_data = decoder(encoded_data)\n",
        "            conc_out.append(decoded_data.cpu())\n",
        "            conc_label.append(image_batch.cpu())\n",
        "        conc_out = torch.cat(conc_out)\n",
        "        conc_label = torch.cat(conc_label)\n",
        "        val_loss = loss_fn(conc_out, conc_label)\n",
        "    return val_loss.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IuKbq73KzKHx",
        "outputId": "396598cf-d38b-4f28-97ba-0135d7b3217a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHE 1/30\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHE \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs))\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m test_epoch(\n\u001b[1;32m     16\u001b[0m         encoder\u001b[38;5;241m=\u001b[39mencoder,\n\u001b[1;32m     17\u001b[0m         decoder\u001b[38;5;241m=\u001b[39mdecoder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         noise_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     history_da[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
            "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(encoder, decoder, device, dataloader, loss_fn, optimizer, noise_factor)\u001b[0m\n\u001b[1;32m      8\u001b[0m image_batch \u001b[38;5;241m=\u001b[39m image_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m noisy_batch \u001b[38;5;241m=\u001b[39m add_noise(image_batch, noise_factor)\n\u001b[0;32m---> 10\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m decoded_data \u001b[38;5;241m=\u001b[39m decoder(encoded_data)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(decoded_data, image_batch)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[23], line 19\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_lin(x)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "history_da = {\"train_loss\": [], \"test_loss\": []}\n",
        "loss_fn = nn.MSELoss()\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"EPOCHE %d/%d\" % (epoch + 1, num_epochs))\n",
        "    train_loss = train_epoch(\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        device=device,\n",
        "        dataloader=train_loader,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        noise_factor=0.3,\n",
        "    )\n",
        "    val_loss = test_epoch(\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        device=device,\n",
        "        dataloader=test_loader,\n",
        "        loss_fn=loss_fn,\n",
        "        noise_factor=0.3,\n",
        "    )\n",
        "    history_da[\"train_loss\"].append(train_loss)\n",
        "    history_da[\"test_loss\"].append(val_loss)\n",
        "    print(\n",
        "        \"\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}\".format(\n",
        "            epoch + 1, num_epochs, train_loss, val_loss\n",
        "        )\n",
        "    )\n",
        "    plot_ae_outputs(encoder=encoder, decoder=decoder, noise_factor=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSzXXbjDzKU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "jyU3RUcU82Cq",
        "outputId": "4979975e-97ff-47b6-d19d-79412305d8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7362131865085972, -0.8336742868210263]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 임의의 숫자를 넣어서 random 으로 decoder 만으로 숫자 그림 생성하기\n",
        "import random\n",
        "\n",
        "random_data = [random.random() * 2 - 1 for _ in range(2)]\n",
        "# random_data = [0.337, 0.49]\n",
        "print(random_data)\n",
        "output = decoder(torch.Tensor(random_data).to(device).reshape(-1, 2))\n",
        "plt.imshow(output.cpu().squeeze().detach().numpy(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D3Orc4m86Yo",
        "outputId": "fd718ae3-6e28-4c4b-8028-bd34d4a32937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5)\n",
            "tensor([[-0.2937, -0.0568]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(0)\n",
            "tensor([[-1.4202,  1.4741]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(4)\n",
            "tensor([[0.3951, 1.1770]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(1)\n",
            "tensor([[ 0.1161, -0.1165]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(9)\n",
            "tensor([[0.3552, 0.4243]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(2)\n",
            "tensor([[ 0.1076, -1.0921]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(1)\n",
            "tensor([[ 0.4377, -0.0127]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(3)\n",
            "tensor([[-0.2711, -0.0906]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(1)\n",
            "tensor([[ 0.4554, -0.0114]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor(4)\n",
            "tensor([[0.1645, 0.1385]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# train data 로 숫자 얻기\n",
        "for i in range(10):\n",
        "    output = encoder(train_dataset.data[i].float().to(device).reshape(1, 1, 28, 28))\n",
        "    print(train_dataset.targets[i])\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgMhvYXK_MEa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6CV6hPwBbK5"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BIqbh4tBcvx",
        "outputId": "5e00625d-7523-4541-e481-c75f20b6d085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NXvjArDKBfbo"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True, pin_memory=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pBsN4hU2Bv1-"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.input2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.LeakyRelu = nn.LeakyReLU(0.2)\n",
        "        self.training = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_ = self.LeakyRelu(self.input1(x))\n",
        "        h_ = self.LeakyRelu(self.input2(h_))\n",
        "        mean = self.mean(h_)\n",
        "        log_var = self.var(h_)\n",
        "        return mean, log_var\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "        self.LeakyRelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.LeakyRelu(self.hidden1(x))\n",
        "        h = self.LeakyRelu(self.hidden2(h))\n",
        "        return torch.sigmoid(self.output(h))\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, Encoder, Decoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.Encoder = Encoder\n",
        "        self.Decoder = Decoder\n",
        "\n",
        "    def reparameterization(self, mean, var):\n",
        "        epsilon = torch.randn_like(var).to(device)\n",
        "        z = mean + var * epsilon\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, log_var = self.Encoder(x)\n",
        "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
        "        x_hat = self.Decoder(z)\n",
        "        return x_hat, mean, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "d163mlyTELMP"
      },
      "outputs": [],
      "source": [
        "x_dim = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 200\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
        "decoder = Decoder(latent_dim=latent_dim, hidden_dim=hidden_dim, output_dim=x_dim)\n",
        "model = Model(Encoder=encoder, Decoder=decoder).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Uqp5mTrGEeey"
      },
      "outputs": [],
      "source": [
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "    return reproduction_loss, KLD\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAfK0HUfEvQ2",
        "outputId": "0d5c1014-8423-4e40-9bef-82ae8c25600e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorboardX in /home/aa/.local/lib/python3.10/site-packages (2.6.4)\n",
            "Requirement already satisfied: numpy in /home/aa/.local/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20 in /home/aa/.local/lib/python3.10/site-packages (from tensorboardX) (5.29.5)\n",
            "Requirement already satisfied: packaging in /home/aa/.local/lib/python3.10/site-packages (from tensorboardX) (25.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (Encoder): Encoder(\n",
              "    (input1): Linear(in_features=784, out_features=400, bias=True)\n",
              "    (input2): Linear(in_features=400, out_features=400, bias=True)\n",
              "    (mean): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (var): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (LeakyRelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              "  (Decoder): Decoder(\n",
              "    (hidden1): Linear(in_features=200, out_features=400, bias=True)\n",
              "    (hidden2): Linear(in_features=400, out_features=400, bias=True)\n",
              "    (output): Linear(in_features=400, out_features=784, bias=True)\n",
              "    (LeakyRelu): LeakyReLU(negative_slope=0.2)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "!pip install tensorboardX\n",
        "# 6 model train function\n",
        "from tensorboardX import SummaryWriter\n",
        "saved_loc = \"scalar/\"\n",
        "writer = SummaryWriter(saved_loc)\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qMt2mdyAFBFV"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "\n",
        "\n",
        "def train(epoch, model, train_loder, optimizer):\n",
        "    train_loss = 0\n",
        "    for batch_idx, (x, _) in enumerate(train_loder):\n",
        "        x = x.view(batch_size, x_dim)\n",
        "        x = x.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_hat, mean, log_var = model(x)\n",
        "        BCE, KLD = loss_function(x, x_hat, mean, log_var)\n",
        "        loss = BCE + KLD\n",
        "        writer.add_scalar(\n",
        "            \"Train/Reconstruction Error\",\n",
        "            BCE.item(),\n",
        "            batch_idx + epoch * len(train_loder.dataset) / batch_size,\n",
        "        )\n",
        "        writer.add_scalar(\n",
        "            \"Train/KL-Divergence\",\n",
        "            KLD.item(),\n",
        "            batch_idx + epoch * len(train_loder.dataset) / batch_size,\n",
        "        )\n",
        "        writer.add_scalar(\n",
        "            \"Train/Total Loss\",\n",
        "            loss.item(),\n",
        "            batch_idx + epoch * len(train_loder.dataset) / batch_size,\n",
        "        )\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(\n",
        "                f\"Train Epoch: {epoch} [{batch_idx * len(x)}/{len(train_loder.dataset)} ({100. * batch_idx / len(train_loder):.0f}%)]\\tLoss: {loss.item() / len(x):.6f}\"\n",
        "            )\n",
        "    print(\n",
        "        \"====> Epoch: {} Average loss: {:.4f}\".format(\n",
        "            epoch, train_loss / len(train_loder.dataset)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "\n",
        "# 7 model test function\n",
        "def test(epoch, model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, _) in enumerate(test_loader):\n",
        "            x = x.view(batch_size, x_dim)\n",
        "            x = x.to(device)\n",
        "            x_hat, mean, log_var = model(x)\n",
        "            BCE, KLD = loss_function(x, x_hat, mean, log_var)\n",
        "            loss = BCE + KLD\n",
        "\n",
        "            writer.add_scalar(\n",
        "                \"Test/Reconstruction Error\",\n",
        "                BCE.item(),\n",
        "                batch_idx + epoch * len(test_loader.dataset) / batch_size,\n",
        "            )\n",
        "            writer.add_scalar(\n",
        "                \"Test/KL-Divergence\",\n",
        "                KLD.item(),\n",
        "                batch_idx + epoch * len(test_loader.dataset) / batch_size,\n",
        "            )\n",
        "            writer.add_scalar(\n",
        "                \"Test/Total Loss\",\n",
        "                loss.item(),\n",
        "                batch_idx + epoch * len(test_loader.dataset) / batch_size,\n",
        "            )\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                n = min(x.size(0), 8)\n",
        "                comparison = torch.cat([x[:n], x_hat.view(batch_size, x_dim)[:n]])\n",
        "                grid = torchvision.utils.make_grid(comparison.cpu())\n",
        "                writer.add_image(\n",
        "                    \"Test image - Above: real data, below: reconstructed data\",\n",
        "                    grid,\n",
        "                    epoch,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 546.614570\n"
          ]
        }
      ],
      "source": [
        "# 8 model train and test\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "for epoch in tqdm(range(0, epochs)):\n",
        "    train(epoch, model, train_loader, optimizer)\n",
        "    test(epoch, model, test_loader)\n",
        "    print(\"\\n\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
